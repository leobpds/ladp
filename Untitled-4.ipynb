{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\jh_to\\anaconda3\\envs\\ladp_env\\lib\\site-packages (5.23.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\jh_to\\anaconda3\\envs\\ladp_env\\lib\\site-packages (1.13.1)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\jh_to\\anaconda3\\envs\\ladp_env\\lib\\site-packages (from plotly) (8.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jh_to\\anaconda3\\envs\\ladp_env\\lib\\site-packages (from plotly) (24.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\jh_to\\anaconda3\\envs\\ladp_env\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jh_to\\anaconda3\\envs\\ladp_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.5.1-cp39-cp39-win_amd64.whl (11.0 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data loaded successfully:\n",
      "                                            Question  \\\n",
      "0                                 what is shell go+?   \n",
      "1           where can i download the shell asia app?   \n",
      "2  what is the fuel discount for private hire sch...   \n",
      "3  what is the fuel discount for taxi scheme memb...   \n",
      "4  what is the fuel discount for bus scheme membe...   \n",
      "\n",
      "                                              Answer  \\\n",
      "0  Shell GO+ is Shell's new and revamped loyalty ...   \n",
      "1  You can download the Shell Asia app from Apple...   \n",
      "2  As a Private Hire scheme member, you'll enjoy ...   \n",
      "3  As a Taxi scheme member, you'll enjoy an upfro...   \n",
      "4  As a Bus scheme member, you'll enjoy an upfron...   \n",
      "\n",
      "                                     Tags  \\\n",
      "0  food retailer, private hire, bus, taxi   \n",
      "1  food retailer, private hire, bus, taxi   \n",
      "2                            private hire   \n",
      "3                                    taxi   \n",
      "4                                     bus   \n",
      "\n",
      "                                             content  \n",
      "0  What is Shell GO+?\\nShell GO+ is Shell's new a...  \n",
      "1  Where can I download the Shell Asia app?\\nYou ...  \n",
      "2  What is the fuel discount for Private Hire sch...  \n",
      "3  What is the fuel discount for Taxi scheme memb...  \n",
      "4  What is the fuel discount for Bus scheme membe...  \n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://8bd5980cd7e31fe26f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8bd5980cd7e31fe26f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: hi\n",
      "User input: discount\n",
      "User input: corporate\n",
      "Searching for: corporate discount\n",
      "No match found in CSV.\n",
      "User input: bus\n",
      "Searching for: bus\n",
      "Found in CSV.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "# Load .env file and get API key, API base, and deployment name:\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"API_KEY\")\n",
    "deployment_name = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "\n",
    "# Leave these 2 lines alone, unless you know what you are doing:\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = '2023-05-15'\n",
    "\n",
    "# Step 1: Load the CSV data\n",
    "def load_csv_data(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Error: File '{file_path}' does not exist.\")\n",
    "    \n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f\"CSV data loaded successfully:\\n{data.head()}\")  # Print the first few rows of the CSV to verify\n",
    "    \n",
    "    required_columns = ['Question', 'Answer', 'Tags', 'content']  # Adjust based on actual CSV columns\n",
    "    if not all(col in data.columns for col in required_columns):\n",
    "        raise ValueError(f\"Error: Missing required columns in CSV file '{file_path}'\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Function to find the best match in the CSV\n",
    "def find_best_csv_match(user_input, dataframe):\n",
    "    print(f\"Searching for: {user_input}\")  # Log the search term\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if user_input.lower() in row['Question'].lower():  # Ensure this matches the CSV column name\n",
    "            return row['Answer']  # Return only the answer\n",
    "    \n",
    "    print(\"No match found in CSV.\")\n",
    "    return None\n",
    "\n",
    "# Handle general queries like \"hi\"\n",
    "def handle_general_queries(user_input):\n",
    "    general_responses = {\n",
    "        \"hi\": \"Hello! How can I assist you today?\",\n",
    "        \"hello\": \"Hi there! What can I help you with?\",\n",
    "        \"how are you\": \"I'm just a bot, but I'm here to help you with any questions!\",\n",
    "        \"goodbye\": \"Goodbye! Feel free to come back if you have more questions.\"\n",
    "    }\n",
    "    \n",
    "    return general_responses.get(user_input.lower(), None)\n",
    "\n",
    "# Handle discount queries by prompting for a segment\n",
    "def handle_discount_query(user_input, context):\n",
    "    if context.get(\"waiting_for_segment\"):\n",
    "        segment = user_input.lower().strip()\n",
    "        context.pop(\"waiting_for_segment\")  # Clear the context flag\n",
    "        # Map user input to specific segment keywords\n",
    "        segment_map = {\n",
    "            \"bus\": \"bus\",\n",
    "            \"corporate\": \"corporate\",\n",
    "            \"private hire\": \"private hire\"\n",
    "        }\n",
    "        if segment in segment_map:\n",
    "            query = f\"{segment_map[segment]} discount\"\n",
    "            csv_response = find_best_csv_match(query, csv_data)\n",
    "            if csv_response:\n",
    "                return csv_response, context\n",
    "            else:\n",
    "                return \"Sorry, I couldn't find any relevant discounts for that segment.\", context\n",
    "        else:\n",
    "            context[\"waiting_for_segment\"] = True\n",
    "            return \"Sorry, I didn't understand that segment. Please choose from Bus, Corporate, or Private Hire.\", context\n",
    "\n",
    "    if \"discount\" in user_input.lower():\n",
    "        context[\"waiting_for_segment\"] = True\n",
    "        return \"Which discount segment are you referring to? Bus? Corporate? Private Hire?\", context\n",
    "\n",
    "    return None, context\n",
    "\n",
    "# Fallback to GPT-3.5 via ChatCompletion API with your provided prompt template\n",
    "def fallback_to_gpt(user_input, context):\n",
    "    try:\n",
    "        print(\"Falling back to GPT-3.5...\")\n",
    "        \n",
    "        # Define the prompt template\n",
    "        prompt_template = (\n",
    "            \"You are a helpful and professional AI customer service assistant representing Best Petrol & Diesel Supply Pte Ltd (Best Petrol) \"\n",
    "            \"and Best Petrol is a joint venture with Shell Singapore Pte Ltd (Shell). \"\n",
    "            \"Your goal is to assist customers by answering their questions and guiding them through various processes. \"\n",
    "            \"When responding to user inquiries, match their questions with the most relevant information from the provided context. \"\n",
    "            \"If the question is too broad and has multiple possible answers related to different products, inform the user that you'll provide options for them to choose from. \"\n",
    "            \"Otherwise, construct your answers precisely based on the exact information in the 'Answer' field with minimal elaboration or additional information. \"\n",
    "            \"Ensure your responses are concise and directly address the user's question related to the 'content' and 'tag' field. \"\n",
    "            \"Based on the selected 'Question', establish the corresponding answer from 'Answer'. \"\n",
    "            \"Write in an informative and instructional style. Ensure clarity and coherence in the presentation of your response. \"\n",
    "            \"Maintain a positive and courteous tone throughout, fostering a sense of empathy, trust and support. \"\n",
    "            \"The target audience is existing Best Petrol customers or potential customers interested in deriving better value for their fuel expenses. \"\n",
    "            \"Assume a readership that seeks useful advice and guidance on Best Petrol's processes. \"\n",
    "            \"Always respond in a courteous and concise manner. \"\n",
    "            \"Limit your response to a maximum of 100 words. If you don't know the answer, apologize and let the customer know that you do not have the answer.\"\n",
    "        )\n",
    "        \n",
    "        # Format the prompt with the user's input\n",
    "        prompt = prompt_template.format(user_input=user_input)\n",
    "        \n",
    "        # Generate the response using the formatted prompt\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=deployment_name,  # Use your specific GPT-3.5 model on Azure\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error with GPT-3.5 fallback: {str(e)}\")\n",
    "        return f\"An error occurred while generating a response: {str(e)}\"\n",
    "\n",
    "# Chatbot response function with CSV, general query handling, and GPT-3.5 fallback\n",
    "def chatbot_response(user_input, context):\n",
    "    try:\n",
    "        print(f\"User input: {user_input}\")  # Log user input\n",
    "\n",
    "        # Step 1: Handle general queries\n",
    "        general_response = handle_general_queries(user_input)\n",
    "        if general_response:\n",
    "            return general_response, context\n",
    "\n",
    "        # Step 2: Handle discount queries\n",
    "        discount_response, context = handle_discount_query(user_input, context)\n",
    "        if discount_response:\n",
    "            return discount_response, context\n",
    "\n",
    "        # Step 3: Search the CSV for a matching FAQ\n",
    "        csv_response = find_best_csv_match(user_input, csv_data)\n",
    "        if csv_response:\n",
    "            print(\"Found in CSV.\")\n",
    "            return csv_response, context\n",
    "        \n",
    "        print(\"Not found in CSV, moving to GPT-3.5.\")\n",
    "\n",
    "        # Step 4: Fallback to GPT-3.5 Turbo if no match in CSV\n",
    "        gpt_response = fallback_to_gpt(user_input, context)\n",
    "        if gpt_response:\n",
    "            print(\"Response from GPT-3.5.\")\n",
    "            return gpt_response, context\n",
    "\n",
    "        print(\"No response generated.\")\n",
    "        return \"I'm sorry, I couldn't find any relevant information.\", context\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in chatbot_response: {str(e)}\")  # Log the error\n",
    "        return f\"An error occurred: {str(e)}\", context\n",
    "\n",
    "# Load your CSV file\n",
    "csv_file_path = r'C:\\Users\\jh_to\\OneDrive\\Desktop\\test\\data\\combined_faq.csv'\n",
    "csv_data = load_csv_data(csv_file_path)\n",
    "\n",
    "# Gradio interface setup with a chat-like design\n",
    "def chat_interface(user_input, state):\n",
    "    if state is None:\n",
    "        state = {\"history\": [], \"context\": {}}  # Initialize history and context\n",
    "    history = state[\"history\"]\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    response, context = chatbot_response(user_input, context)\n",
    "    history.append((user_input, response))\n",
    "    \n",
    "    state[\"history\"] = history\n",
    "    state[\"context\"] = context\n",
    "    return state[\"history\"], state\n",
    "\n",
    "# Improved Gradio Interface with chat-like appearance and placeholder text\n",
    "iface = gr.Interface(\n",
    "    fn=chat_interface,\n",
    "    inputs=[gr.Textbox(lines=1, placeholder=\"Ask me a question...\"), \"state\"],\n",
    "    outputs=[\"chatbot\", \"state\"],\n",
    "    title=\"Best Petrol & Diesel Supply Chatbot\",\n",
    "    description=\"Welcome! How can I assist you today?\",\n",
    "    examples=[[\"What is Shell GO+\"], [\"Where can I download the Shell app?\"]],\n",
    "    allow_flagging=\"never\"  # Disable flagging for customer-facing products\n",
    ")\n",
    "\n",
    "# Launch the interface with public sharing enabled\n",
    "iface.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ladp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
